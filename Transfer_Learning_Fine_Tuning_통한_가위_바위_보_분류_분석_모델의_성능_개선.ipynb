{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning Fine-Tuning 통한 가위-바위-보 분류 분석 모델의 성능 개선.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olive-su/AI_codepresso/blob/master/Transfer_Learning_Fine_Tuning_%ED%86%B5%ED%95%9C_%EA%B0%80%EC%9C%84_%EB%B0%94%EC%9C%84_%EB%B3%B4_%EB%B6%84%EB%A5%98_%EB%B6%84%EC%84%9D_%EB%AA%A8%EB%8D%B8%EC%9D%98_%EC%84%B1%EB%8A%A5_%EA%B0%9C%EC%84%A0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGEqpQmA_WZ6"
      },
      "source": [
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Bht6Z5Cbnm_"
      },
      "source": [
        "## Transfer Learning 을 통한 가위-바위-보 분류 데이터 셋 분류 성능 개선"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhbHXd2ZI1t3"
      },
      "source": [
        "### Step 1. Input tensor 와 Target tensor 준비(훈련데이터)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axECPsnlb5lA"
      },
      "source": [
        "(1) 가위-바위-보 데이터셋 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpywvV4KMjIE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da131a3f-143b-46da-aba6-75bf484c4f25"
      },
      "source": [
        "url = 'https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps.zip'\n",
        "\n",
        "path_to_zip = keras.utils.get_file('rps.zip',\n",
        "                                   origin=url,\n",
        "                                   extract=True,\n",
        "                                   cache_dir='/content')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps.zip\n",
            "200687616/200682221 [==============================] - 2s 0us/step\n",
            "200695808/200682221 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CFDzcUpM2wJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d63d0a2-2889-4f2f-b1bf-3b75a18fa26d"
      },
      "source": [
        "url = 'https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps-test-set.zip'\n",
        "\n",
        "path_to_zip = keras.utils.get_file('rps_test.zip',\n",
        "                                   origin=url,\n",
        "                                   extract=True,\n",
        "                                   cache_dir='/content')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps-test-set.zip\n",
            "29523968/29516758 [==============================] - 0s 0us/step\n",
            "29532160/29516758 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5iHfTAhb-SM"
      },
      "source": [
        "(2) ImageDataGenerator를 이용해 이미지 파일을 load 하기 위한 경로 지정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmGW7BsTNbRz"
      },
      "source": [
        "train_dir = '/content/datasets/rps'\n",
        "test_dir = '/content/datasets/rps-test-set'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJj4NG2ucAfU"
      },
      "source": [
        "(3) ImageDataGenerator 객체 생성  \n",
        "* 객체 생성 시 rescale 인자를 이용하여 텐서 내 원소의 범위를 [0 ~ 255] => [0 ~ 1] 로 ReScaling 진행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DT1tnXgMoo0"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toobDJJUMslq"
      },
      "source": [
        "# 모든 이미지를 1/255로 스케일을 조정합니다\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   validation_split=0.2)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsAYG-IhcgsL"
      },
      "source": [
        "* .flow_from_directory() 메서드를 이용하여 학습데이터와 검증데이터를 위한 DirectoryIterator 객체 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWdw-5EKMywK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1e02ec0-364b-40b1-9afa-96ef4fa4b19c"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=20,\n",
        "        shuffle=True,\n",
        "        class_mode='categorical',\n",
        "        subset='training',\n",
        "        seed=7)\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=20,\n",
        "        shuffle=True,\n",
        "        class_mode='categorical',\n",
        "        subset='validation',\n",
        "        seed=7)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=20,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2016 images belonging to 3 classes.\n",
            "Found 504 images belonging to 3 classes.\n",
            "Found 372 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stk917_Sci0V"
      },
      "source": [
        "### Step 2. VGG16을 Backbone 으로 하는 모델 디자인 및 학습 정보 설정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BP8hv-ZCcnQx"
      },
      "source": [
        "(1) Pre-trained 된 VGG16 모델 객체 생성\n",
        "  * imagenet 데이터를 이용해 학습된 모델 객체 생성\n",
        "  * classification layer 제외"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsBdZgjQS_9m"
      },
      "source": [
        "from tensorflow.keras.applications import VGG16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHsguOaF7CMR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f24f4ae-a8f0-4a65-ca9b-ce8db663f5bf"
      },
      "source": [
        "conv_base = VGG16(include_top=False,\n",
        "                  weights='imagenet',\n",
        "                  input_shape=(224, 224, 3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "58900480/58889256 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiqnkRJZ2SHO",
        "outputId": "3b9cfbac-220f-4dd5-bea3-4e06becd7f29"
      },
      "source": [
        "conv_base.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18TfCRgEc_mb"
      },
      "source": [
        "(2) VGG16 Backbone 모델에 classification layer 추가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnwc5pXX3f8x"
      },
      "source": [
        "model = keras.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xe8HApyF8YEk"
      },
      "source": [
        "model.add(conv_base)\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(256, activation='relu'))\n",
        "model.add(keras.layers.Dense(3, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_hBr1cJ4Hzd",
        "outputId": "5bd19906-7e46-483d-94f4-3db0df47b452"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               6422784   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 21,138,243\n",
            "Trainable params: 21,138,243\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4g29WFrdQYm"
      },
      "source": [
        "(3) VGG16 Backbone 모델의 가중치 동결(학습대상 가중치에서 제외)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDhAapMbd8jW"
      },
      "source": [
        "* VGG16 Backbone 모델의 가중치 중 마지막 Conv2D Layer(block5_conv3) 를 제외한 layer 들의 가중치 동결"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHUnRXobd4aW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "999486d5-965e-44f1-d61a-acd524aeafba"
      },
      "source": [
        "len(model.trainable_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pf5B8IQ7GEMD"
      },
      "source": [
        "> * 방법1. conv_base 객체에서 .layers 속성 정보를 이용하여 모델에 추가되어 있는 layer 객체 들에 접근 하여 loop 돌면서 name 이 `block5_conv3` 인 layer를 제외 하고 동결 처리\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYorLNyE9do9"
      },
      "source": [
        "for layer in conv_base.layers:\n",
        "  if layer.name == 'block5_conv3':    \n",
        "    continue\n",
        "  layer.trainable=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rv_16I3U6TbL",
        "outputId": "6b43c0eb-d456-49b1-cf4e-8a74b28f802c"
      },
      "source": [
        "len(model.trainable_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NiatPQSGyiT"
      },
      "source": [
        "conv_base.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bg2lYdyEG5Gs"
      },
      "source": [
        "> * 방법2. conv_base 객체에서 .layers 속성 정보를 이용하여 모델에 추가되어 있는 layer 객체 들에 접근 하여 loop 돌면서 동결 처리 후 동결에서 제외 하고자 하는 layer 선택하여 동결 해제\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eq4VlU75HLVp",
        "outputId": "f9f4bc28-cdca-49c8-9d29-a91dc6b2ebb3"
      },
      "source": [
        "len(model.trainable_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSXoaSOiHEoj"
      },
      "source": [
        "for layer in conv_base.layers:\n",
        "  layer.trainable=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzcTRCUVHNoL",
        "outputId": "6df26e4b-f017-4844-8222-0f629ec01d94"
      },
      "source": [
        "len(model.trainable_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5feRHXqHOwQ"
      },
      "source": [
        "conv_base.layers[-2].trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ed6yq9O4HUOS",
        "outputId": "98eae4f8-83ed-4817-f2e6-0c2b9d935e1c"
      },
      "source": [
        "len(model.trainable_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnSLvQov9om0",
        "outputId": "1cf0dfac-3bee-4bce-bac1-f96248cfcc73"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               6422784   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 21,138,243\n",
            "Trainable params: 8,783,363\n",
            "Non-trainable params: 12,354,880\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p58Gw79MePBh"
      },
      "source": [
        "(4) 학습을 위한 설정 정보 지정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spdqys60-4x4"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.RMSprop(learning_rate=2e-5),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3D-ob5jkfmZe"
      },
      "source": [
        "### Step 3. 모델에 데이터 generator 연결 후 학습 \n",
        "  * model.fit() 이용하여 데이터 연결 및 학습시키기\n",
        "  * 학습 과정은 history 변수에 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIl1NAH2-8Js",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6280edc1-b9d4-4f0a-abd7-96ad3f625298"
      },
      "source": [
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=len(train_generator),\n",
        "      epochs=30,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=len(validation_generator))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "101/101 [==============================] - 18s 136ms/step - loss: 0.1453 - accuracy: 0.9727 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "101/101 [==============================] - 12s 114ms/step - loss: 6.9359e-04 - accuracy: 1.0000 - val_loss: 3.4839e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "101/101 [==============================] - 12s 114ms/step - loss: 6.0406e-05 - accuracy: 1.0000 - val_loss: 5.7172e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "101/101 [==============================] - 11s 113ms/step - loss: 8.5994e-07 - accuracy: 1.0000 - val_loss: 2.4726e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "101/101 [==============================] - 11s 113ms/step - loss: 1.3322e-07 - accuracy: 1.0000 - val_loss: 1.2773e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "101/101 [==============================] - 11s 112ms/step - loss: 5.6293e-08 - accuracy: 1.0000 - val_loss: 1.1748e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "101/101 [==============================] - 11s 112ms/step - loss: 3.4355e-08 - accuracy: 1.0000 - val_loss: 7.4204e-06 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "101/101 [==============================] - 11s 113ms/step - loss: 2.3653e-08 - accuracy: 1.0000 - val_loss: 6.2757e-06 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "101/101 [==============================] - 11s 112ms/step - loss: 1.8745e-08 - accuracy: 1.0000 - val_loss: 6.4047e-06 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "101/101 [==============================] - 11s 113ms/step - loss: 1.4960e-08 - accuracy: 1.0000 - val_loss: 5.3656e-06 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "101/101 [==============================] - 11s 113ms/step - loss: 1.2891e-08 - accuracy: 1.0000 - val_loss: 5.7395e-06 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "101/101 [==============================] - 11s 112ms/step - loss: 1.0998e-08 - accuracy: 1.0000 - val_loss: 5.2867e-06 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "101/101 [==============================] - 11s 113ms/step - loss: 9.6976e-09 - accuracy: 1.0000 - val_loss: 5.2732e-06 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "101/101 [==============================] - 11s 114ms/step - loss: 8.4558e-09 - accuracy: 1.0000 - val_loss: 4.9618e-06 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "101/101 [==============================] - 11s 112ms/step - loss: 7.3914e-09 - accuracy: 1.0000 - val_loss: 4.5785e-06 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "101/101 [==============================] - 11s 112ms/step - loss: 6.9184e-09 - accuracy: 1.0000 - val_loss: 4.5260e-06 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "101/101 [==============================] - 11s 112ms/step - loss: 5.9723e-09 - accuracy: 1.0000 - val_loss: 4.2796e-06 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "101/101 [==============================] - 11s 112ms/step - loss: 5.6766e-09 - accuracy: 1.0000 - val_loss: 4.7170e-06 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "101/101 [==============================] - 11s 112ms/step - loss: 5.2627e-09 - accuracy: 1.0000 - val_loss: 3.8963e-06 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "101/101 [==============================] - 11s 113ms/step - loss: 4.9671e-09 - accuracy: 1.0000 - val_loss: 4.0452e-06 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "101/101 [==============================] - 11s 111ms/step - loss: 4.6714e-09 - accuracy: 1.0000 - val_loss: 3.5182e-06 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "101/101 [==============================] - 11s 112ms/step - loss: 4.3757e-09 - accuracy: 1.0000 - val_loss: 3.2969e-06 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "101/101 [==============================] - 11s 112ms/step - loss: 4.0801e-09 - accuracy: 1.0000 - val_loss: 3.5699e-06 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "101/101 [==============================] - 11s 112ms/step - loss: 3.9618e-09 - accuracy: 1.0000 - val_loss: 3.4049e-06 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "101/101 [==============================] - 11s 112ms/step - loss: 3.6070e-09 - accuracy: 1.0000 - val_loss: 2.9152e-06 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "101/101 [==============================] - 11s 112ms/step - loss: 3.7253e-09 - accuracy: 1.0000 - val_loss: 2.9563e-06 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "101/101 [==============================] - 11s 111ms/step - loss: 3.3705e-09 - accuracy: 1.0000 - val_loss: 3.0473e-06 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "101/101 [==============================] - 11s 112ms/step - loss: 3.0748e-09 - accuracy: 1.0000 - val_loss: 2.9743e-06 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "101/101 [==============================] - 11s 110ms/step - loss: 3.0157e-09 - accuracy: 1.0000 - val_loss: 3.0696e-06 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "101/101 [==============================] - 11s 110ms/step - loss: 2.9566e-09 - accuracy: 1.0000 - val_loss: 3.0312e-06 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PS8aRYN_YJa"
      },
      "source": [
        "### Step 4. 테스트 데이터 셋을 통한 모델의 성능 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQarZ9C3f64d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3442cd7c-ecc1-4c06-8ca1-23c05bb2bd6c"
      },
      "source": [
        "loss, accuracy = model.evaluate(test_generator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19/19 [==============================] - 3s 153ms/step - loss: 0.0849 - accuracy: 0.9597\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}